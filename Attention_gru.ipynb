{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention gru",
      "provenance": [],
      "collapsed_sections": [
        "JKMAxSPSkGMn",
        "LNKYhUbczLpT",
        "Ltn1UPOo4CBL",
        "B7Kx6HcZHPQf",
        "pj8X_J-qbfSX"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKMAxSPSkGMn",
        "colab_type": "text"
      },
      "source": [
        "# 1. Download Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BowrGOBIrLi9",
        "colab_type": "text"
      },
      "source": [
        "# 2. Preprocessing\n",
        "This is just a very navie preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFe-IEbNDn5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_train = pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "df_test= pd.read_csv('/content/drive/My Drive/test.csv')\n",
        "df_val= pd.read_csv('/content/drive/My Drive/val.csv')\n",
        "df_train.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTuswiVDEOyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=[sentence.split() for sentence in df_train.Sentence]\n",
        "target_y_train=[sentence.split() for sentence in df_train.NER]\n",
        "\n",
        "test_data=[sentence.split() for sentence in df_test.Sentence]\n",
        "# target_y_test=[sentence.split() for sentence in df_test.NER]\n",
        "\n",
        "validation_data=[sentence.split() for sentence in df_val.Sentence]\n",
        "target_y_validation=[sentence.split() for sentence in df_val.NER]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv0FyV32EO1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fe9b80c1-3cdd-44eb-e814-af81a50ea459"
      },
      "source": [
        "word_to_ix = {}\n",
        "for sentence in train_data+validation_data+test_data:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in target_y_train+target_y_validation:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n",
        "\n",
        "tag_list=list(tag_to_ix)\n",
        "print('Word list length: ',len(word_list))\n",
        "print(tag_to_ix)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word list length:  13972\n",
            "{'<START>': 0, '<STOP>': 1, 'O': 2, 'I-ORG': 3, 'I-MISC': 4, 'I-PER': 5, 'I-LOC': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GHzdMJvEO4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_data,word_to_ix)\n",
        "train_output_index = to_index(target_y_train,tag_to_ix)\n",
        "val_input_index = to_index(validation_data,word_to_ix)\n",
        "val_output_index = to_index(target_y_validation,tag_to_ix)\n",
        "test_input_index = to_index(test_data,word_to_ix)\n",
        "# test_output_index = to_index(target_y_test,tag_to_ix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuZIp8qNMwZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe781c17-45d3-48ce-fa4f-c6c26933d301"
      },
      "source": [
        "MAX_LENGTH=max([len(s) for s in train_input_index+val_input_index+test_input_index])\n",
        "MAX_LENGTH"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BrYw7SkzI67",
        "colab_type": "text"
      },
      "source": [
        "# 3. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNKYhUbczLpT",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S2e50gc2qnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUbLYEdzKYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, embedding):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = embedding\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden) \n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltn1UPOo4CBL",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX1GVIjH4D1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    ATTN_TYPE_DOT_PRODUCT = \"Dot Product\"\n",
        "    ATTN_TYPE_SCALE_DOT_PRODUCT = \"Scale Dot Product\"\n",
        "\n",
        "    def __init__(self, hidden_size, output_size, embedding, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = embedding\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "\n",
        "\n",
        "    def cal_attention(self, hidden, encoder_hiddens, method):\n",
        "        if method == AttnDecoderRNN.ATTN_TYPE_DOT_PRODUCT:\n",
        "            # bmm: https://pytorch.org/docs/master/generated/torch.bmm.html\n",
        "            attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "\n",
        "        return concat_output\n",
        "\n",
        "    def forward(self, input, hidden, encoder_hiddens):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        _, hidden = self.gru(embedded, hidden)\n",
        "\n",
        "        concat_output = self.cal_attention(hidden, encoder_hiddens, AttnDecoderRNN.ATTN_TYPE_DOT_PRODUCT)\n",
        "\n",
        "        output = F.log_softmax(self.out(concat_output), dim=1)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Kx6HcZHPQf",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eV2zpmrHQwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_hiddens = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "        encoder_hiddens[i] = encoder_hidden[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[0]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # Teacher forcing: Feed the target as the next input\n",
        "    for i in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hiddens)\n",
        "        loss += criterion(decoder_output, target_tensor[i])\n",
        "        decoder_input = target_tensor[i]  # Teacher forcing\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj8X_J-qbfSX",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Train Iterations Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HRzWVav5k_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESFqV77BS4MC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    \n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        random_choice_ix = random.choice(range(n_data))\n",
        "        input_index_r = [[ind] for ind in input_index[random_choice_ix]]\n",
        "        target_index_r = [[ind] for ind in target_index[random_choice_ix]]\n",
        "        \n",
        "        input_tensor = torch.LongTensor(input_index_r).to(device)\n",
        "        target_tensor = torch.LongTensor(target_index_r).to(device)\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2gi4JzBbkCH",
        "colab_type": "text"
      },
      "source": [
        "# 4. Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPmXTmVNGwzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_index=train_input_index\n",
        "target_index=train_output_index\n",
        "n_data=200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8wff0pfY6diW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "3650bab2-1275-4de7-9c7d-746798218d14"
      },
      "source": [
        "hidden_size = 50\n",
        "embedding = nn.Embedding(len(word_to_ix), hidden_size)\n",
        "encoder1 = EncoderRNN(len(word_to_ix), hidden_size, embedding).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, len(tag_to_ix),embedding, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 1000, print_every=50)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 3s (- 1m 0s) (50 5%) 0.8685\n",
            "0m 6s (- 0m 56s) (100 10%) 0.7176\n",
            "0m 9s (- 0m 55s) (150 15%) 0.7396\n",
            "0m 12s (- 0m 51s) (200 20%) 0.6211\n",
            "0m 16s (- 0m 48s) (250 25%) 0.6798\n",
            "0m 20s (- 0m 47s) (300 30%) 0.6007\n",
            "0m 23s (- 0m 44s) (350 35%) 0.5925\n",
            "0m 27s (- 0m 41s) (400 40%) 0.6154\n",
            "0m 30s (- 0m 37s) (450 45%) 0.7323\n",
            "0m 34s (- 0m 34s) (500 50%) 0.5793\n",
            "0m 37s (- 0m 30s) (550 55%) 0.5794\n",
            "0m 40s (- 0m 26s) (600 60%) 0.5144\n",
            "0m 44s (- 0m 23s) (650 65%) 0.5938\n",
            "0m 47s (- 0m 20s) (700 70%) 0.6983\n",
            "0m 51s (- 0m 17s) (750 75%) 0.5938\n",
            "0m 55s (- 0m 13s) (800 80%) 0.5360\n",
            "0m 59s (- 0m 10s) (850 85%) 0.5748\n",
            "1m 2s (- 0m 6s) (900 90%) 0.5755\n",
            "1m 6s (- 0m 3s) (950 95%) 0.5620\n",
            "1m 9s (- 0m 0s) (1000 100%) 0.5611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nBmWxjhU6q9l"
      },
      "source": [
        "# 5. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hjJxQROt6q9m",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, input_index, max_length=MAX_LENGTH):\n",
        "    # with torch.no_grad():\n",
        "        \n",
        "        input_tensor = torch.LongTensor([[ind] for ind in input_index]).to(device)\n",
        "\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_hiddens = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_hiddens[ei] += encoder_hidden[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[0]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoded_index = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hiddens)\n",
        "            \n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            # print(topi.item())\n",
        "            decoded_index.append(topi.item())\n",
        "            if topi.item() == 1:\n",
        "                decoded_words.append('<STOP>')\n",
        "                \n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(tag_list[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words,decoded_index,decoder_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIbZG0vL7Bci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=[]\n",
        "for s in val_input_index:\n",
        "  _,output_s,_=evaluate(encoder1, attn_decoder1, s, max_length=MAX_LENGTH)\n",
        "  y_pred.append(output_s)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPmCsGu99Zwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ca00b3f1-ca5f-419b-cc66-aa19e11c2d0e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_output_index,y_pred,digits=4))\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-4f51658c0fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_output_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1969\u001b[0m     \"\"\"\n\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[1;32m     80\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    258\u001b[0m         if (not hasattr(y[0], '__array__') and isinstance(y[0], Sequence)\n\u001b[1;32m    259\u001b[0m                 and not isinstance(y[0], str)):\n\u001b[0;32m--> 260\u001b[0;31m             raise ValueError('You appear to be using a legacy multi-label data'\n\u001b[0m\u001b[1;32m    261\u001b[0m                              \u001b[0;34m' representation. Sequence of sequences are no'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                              \u001b[0;34m' longer supported; use a binary array or sparse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
          ]
        }
      ]
    }
  ]
}